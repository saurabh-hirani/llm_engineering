{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe37963-1af6-44fc-a841-8e462443f5e6",
   "metadata": {},
   "source": [
    "# Welcome to RAG week!! (OpenRouter Version)\n",
    "\n",
    "## Expert Knowledge Worker\n",
    "\n",
    "### A question answering Assistant that is an expert knowledge worker\n",
    "### To be used by employees of Insurellm, an Insurance Tech company\n",
    "### The AI assistant needs to be accurate and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy.\n",
    "\n",
    "This first implementation will use a simplistic, brute-force type of RAG..\n",
    "\n",
    "**Modified to work with OpenRouter API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba2779af-84ef-4227-9e9e-6eaf0df87e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9258e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenRouter API Key exists and begins sk-or-v1\n"
     ]
    }
   ],
   "source": [
    "# Setting up OpenRouter\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# OpenRouter configuration\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "if openrouter_api_key:\n",
    "    print(f\"OpenRouter API Key exists and begins {openrouter_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenRouter API Key not set\")\n",
    "\n",
    "MODEL = \"deepseek/deepseek-chat\"\n",
    "\n",
    "# Initialize OpenAI client with OpenRouter endpoint\n",
    "openai = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=openrouter_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "010353af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: deepseek/deepseek-chat\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db802f8",
   "metadata": {},
   "source": [
    "### Let's read in all employee data into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e0652c2-3d76-40c7-8313-9dc1895155a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kim knowledge-base/employees/David Kim.md\n",
      "Patel knowledge-base/employees/Nina Patel.md\n",
      "Sharma knowledge-base/employees/Priya Sharma.md\n",
      "Chen knowledge-base/employees/Alex Chen.md\n",
      "Chen knowledge-base/employees/Robert Chen.md\n",
      "Spencer knowledge-base/employees/Oliver Spencer.md\n",
      "Foster knowledge-base/employees/Amanda Foster.md\n",
      "Tran knowledge-base/employees/Emily Tran.md\n",
      "Blake knowledge-base/employees/Jordan Blake.md\n",
      "Zhang knowledge-base/employees/Kevin Zhang.md\n",
      "Thompson knowledge-base/employees/Maya Thompson.md\n",
      "Adams knowledge-base/employees/Jennifer Adams.md\n",
      "Liu knowledge-base/employees/Jessica Liu.md\n",
      "Lancaster knowledge-base/employees/Avery Lancaster.md\n",
      "Thompson knowledge-base/employees/Maxine Thompson.md\n",
      "Park knowledge-base/employees/Daniel Park.md\n",
      "Greene knowledge-base/employees/Samantha Greene.md\n",
      "Johnson knowledge-base/employees/Marcus Johnson.md\n",
      "Thomson knowledge-base/employees/Alex Thomson.md\n",
      "O'Brien knowledge-base/employees/Michael O'Brien.md\n",
      "Martinez knowledge-base/employees/Rachel Martinez.md\n",
      "Williams knowledge-base/employees/Sarah Williams.md\n",
      "Rivera knowledge-base/employees/Michelle Rivera.md\n",
      "Trenton knowledge-base/employees/Samuel Trenton.md\n",
      "Anderson knowledge-base/employees/Lisa Anderson.md\n",
      "Harper knowledge-base/employees/Alex Harper.md\n",
      "Rodriguez knowledge-base/employees/Carlos Rodriguez.md\n",
      "Wilson knowledge-base/employees/James Wilson.md\n",
      "Bishop knowledge-base/employees/Jordan K. Bishop.md\n",
      "Carter knowledge-base/employees/Emily Carter.md\n",
      "Brooks knowledge-base/employees/Tyler Brooks.md\n",
      "Walker knowledge-base/employees/Brandon Walker.md\n"
     ]
    }
   ],
   "source": [
    "knowledge = {}\n",
    "\n",
    "filenames = glob.glob(\"knowledge-base/employees/*\")\n",
    "\n",
    "for filename in filenames:\n",
    "    name = Path(filename).stem.split(' ')[-1]\n",
    "    print(name, filename)\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        knowledge[name.lower()] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9932835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 employee records\n",
      "Available employees: ['kim', 'patel', 'sharma', 'chen', 'spencer', 'foster', 'tran', 'blake', 'zhang', 'thompson', 'adams', 'liu', 'lancaster', 'park', 'greene', 'johnson', 'thomson', \"o'brien\", 'martinez', 'williams', 'rivera', 'trenton', 'anderson', 'harper', 'rodriguez', 'wilson', 'bishop', 'carter', 'brooks', 'walker']\n"
     ]
    }
   ],
   "source": [
    "# Show available employees\n",
    "print(f\"Loaded {len(knowledge)} employee records\")\n",
    "print(\"Available employees:\", list(knowledge.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1d231f9-091e-4c72-b0f8-6af578a74e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rellm knowledge-base/products/Rellm.md\n",
      "Claimllm knowledge-base/products/Claimllm.md\n",
      "Bizllm knowledge-base/products/Bizllm.md\n",
      "Lifellm knowledge-base/products/Lifellm.md\n",
      "Healthllm knowledge-base/products/Healthllm.md\n",
      "Markellm knowledge-base/products/Markellm.md\n",
      "Homellm knowledge-base/products/Homellm.md\n",
      "Carllm knowledge-base/products/Carllm.md\n"
     ]
    }
   ],
   "source": [
    "# Load product data\n",
    "filenames = glob.glob(\"knowledge-base/products/*\")\n",
    "\n",
    "for filename in filenames:\n",
    "    name = Path(filename).stem\n",
    "    print(name, filename)\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        knowledge[name.lower()] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aba46a57-d973-4195-8fe3-70fc60687192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total knowledge base entries: 38\n",
      "All available keys: ['kim', 'patel', 'sharma', 'chen', 'spencer', 'foster', 'tran', 'blake', 'zhang', 'thompson', 'adams', 'liu', 'lancaster', 'park', 'greene', 'johnson', 'thomson', \"o'brien\", 'martinez', 'williams', 'rivera', 'trenton', 'anderson', 'harper', 'rodriguez', 'wilson', 'bishop', 'carter', 'brooks', 'walker', 'rellm', 'claimllm', 'bizllm', 'lifellm', 'healthllm', 'markellm', 'homellm', 'carllm']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total knowledge base entries: {len(knowledge)}\")\n",
    "print(\"All available keys:\", list(knowledge.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "129c7d1e-0094-4479-9459-f9360b95f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PREFIX = \"\"\"\n",
    "You represent Insurellm, the Insurance Tech company.\n",
    "You are an expert in answering questions about Insurellm; its employees and its products.\n",
    "You are provided with additional context that might be relevant to the user's question.\n",
    "Give brief, accurate answers. If you don't know the answer, say so.\n",
    "\n",
    "Relevant context:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c94ea125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    text = ''.join(ch for ch in message if ch.isalpha() or ch.isspace())\n",
    "    words = text.lower().split()\n",
    "    return [knowledge[word] for word in words if word in knowledge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a7cef7f-f214-4bac-8217-3f9ab9ba1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if not relevant_context:\n",
    "        result = \"There is no additional context relevant to the user's question.\"\n",
    "    else:\n",
    "        result = \"The following additional context might be relevant in answering the user's question:\\n\\n\"\n",
    "        result += \"\\n\\n\".join(relevant_context)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e7bf2-e862-4679-a11f-6c1efb6ec8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    system_message = SYSTEM_PREFIX + additional_context(message)\n",
    "    print(system_message)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    print(messages)\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=1000,\n",
    "            temperature=0\n",
    "        )\n",
    "        print(response)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcb659-13ce-47ab-8a5e-01b930494964",
   "metadata": {},
   "source": [
    "## Test the chat function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "test-chat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='gen-1767898062-Q2euDWdWEgx58tH9kx0F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Avery Lancaster is the Co-Founder and CEO of Insurellm. She has led the company since its inception in 2015, driving innovation and growth in the Insurance Tech sector. Currently based in San Francisco, she earns a $225,000 salary and has been recognized for her leadership, particularly in navigating challenges like the COVID-19 pandemic and fostering diversity initiatives. Prior to Insurellm, she held roles at Innovate Insurance Solutions and Edge Analytics.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1767898062, model='deepseek/deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='', usage=CompletionUsage(completion_tokens=95, prompt_tokens=989, total_tokens=1084, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, image_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, video_tokens=0), cost=0.0005191, is_byok=False, cost_details={'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0.0003956, 'upstream_inference_completions_cost': 0.0001235}), provider='Novita')\n",
      "Avery Lancaster is the Co-Founder and CEO of Insurellm. She has led the company since its inception in 2015, driving innovation and growth in the Insurance Tech sector. Currently based in San Francisco, she earns a $225,000 salary and has been recognized for her leadership, particularly in navigating challenges like the COVID-19 pandemic and fostering diversity initiatives. Prior to Insurellm, she held roles at Innovate Insurance Solutions and Edge Analytics.\n"
     ]
    }
   ],
   "source": [
    "# Test the chat function\n",
    "test_response = chat(\"Who is Lancaster?\", [])\n",
    "print(test_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradio-interface",
   "metadata": {},
   "source": [
    "## Launch Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3536590-85c7-4155-bd87-ae78a1467670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='gen-1767898076-9O7Obo4CYCSYNvbV6aEc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Insurellm is an Insurance Tech company focused on leveraging technology to innovate and improve insurance solutions. If you have specific questions about its products or services, feel free to ask!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1767898076, model='deepseek/deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='', usage=CompletionUsage(completion_tokens=36, prompt_tokens=90, total_tokens=126, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, image_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, video_tokens=0), cost=8.28e-05, is_byok=False, cost_details={'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 3.6e-05, 'upstream_inference_completions_cost': 4.68e-05}), provider='Novita')\n",
      "ChatCompletion(id='gen-1767898088-ECEHR2hWuTAtwgJV2B5F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Yes, Insurellm is a real company in the insurance technology (InsurTech) sector. If you're looking for specific details about its products, services, or legitimacy, let me know how I can help!\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1767898088, model='deepseek/deepseek-chat', object='chat.completion', service_tier=None, system_fingerprint='', usage=CompletionUsage(completion_tokens=46, prompt_tokens=133, total_tokens=179, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=None, reasoning_tokens=0, rejected_prediction_tokens=None, image_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, video_tokens=0), cost=0.000113, is_byok=False, cost_details={'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 5.32e-05, 'upstream_inference_completions_cost': 5.98e-05}), provider='Novita')\n"
     ]
    }
   ],
   "source": [
    "# Launch Gradio chat interface\n",
    "view = gr.ChatInterface(\n",
    "    chat,\n",
    "    type=\"messages\",\n",
    "    title=\"Insurellm Knowledge Assistant (OpenRouter)\",\n",
    "    description=f\"Ask questions about Insurellm employees and products. Using {MODEL} via OpenRouter.\"\n",
    ").launch(inbrowser=True, share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
